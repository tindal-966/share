> From: http://www.cs.umd.edu/~pugh/java/memoryModel/jsr-133-faq.html

# JSR 133 (Java Memory Model) FAQ
Jeremy Manson and Brian Goetz, February 2004

## Table of Contents
> 译注：建议可以只读加粗内容，剩下的内容可以到 JSR-133 中阅读（不可完全相信翻译、译注内容）

- **What is a memory model, anyway?**
- Do other languages, like C++, have a memory model?
- **What is JSR 133 about?**
- **What is meant by reordering?**
- What was wrong with the old memory model?
- **What do you mean by incorrectly synchronized?**
- What does synchronization do?
- How can final fields appear to change their values?
- How do final fields work under the new JMM?
- What does volatile do?
- Does the new memory model fix the "double-checked locking" problem?
- What if I'm writing a VM?
- Why should I care?

## What is a memory model, anyway? 内存模型究竟是什么？
In multiprocessor systems, processors generally have one or more layers of memory cache, which improves performance both by speeding access to data (because the data is closer to the processor) and reducing traffic on the shared memory bus (because many memory operations can be satisfied by local caches.) Memory caches can improve performance tremendously, but they present a host of new challenges. What, for example, happens when two processors examine the same memory location at the same time? Under what conditions will they see the same value?

大意：多处理器系统中存在处理器缓存（L1~L3 Cache），在提高性能的同时带来了问题。例如：当两个处理器同时检查同一个内存位置时会发生什么？在什么条件下它们会看到相同的值？即内存一致性 Memory Consistency 问题

At the processor level, a memory model defines necessary and sufficient conditions for knowing that writes to memory by other processors are visible to the current processor, and writes by the current processor are visible to other processors. Some processors exhibit a strong memory model, where all processors see exactly the same value for any given memory location at all times. Other processors exhibit a weaker memory model, where special instructions, called memory barriers, are required to flush or invalidate the local processor cache in order to see writes made by other processors or make writes by this processor visible to others. These memory barriers are usually performed when lock and unlock actions are taken; they are invisible to programmers in a high level language.

在处理器层面，内存模型定义了必要和充分的条件，即知道其他处理器对内存的写入对当前处理器是可见的，而当前处理器的写入对其他处理器是可见的。一些处理器表现出强内存模型 strong memory model，即所有处理器在任何时候都能看到任何给定内存位置的完全相同的值。**其他处理器表现出一种较弱内存模型 weaker memory model，在这种模型中，需要有被称为内存屏障 memory barriers 的特殊指令来刷新 flush 或废止 invalidate 本地处理器的缓存，以便看到其他处理器的写入，或使本处理器的写入对其他人可见**。这些内存障碍通常是在进行锁定 lock 和解锁 unlock 操作时出现；在高级语言中，内存屏障是程序员不可见的。

> 译注：处理器层面的 memory model 定义了在什么条件下，其他处理器...内存写入...可见，当前处理...内存写入...可见。

It can sometimes be easier to write programs for strong memory models, because of the reduced need for memory barriers. However, even on some of the strongest memory models, memory barriers are often necessary; quite frequently their placement is counterintuitive. Recent trends in processor design have encouraged weaker memory models, because the relaxations they make for cache consistency allow for greater scalability across multiple processors and larger amounts of memory.

大意：strong memory model 编写程序更容易，但 weaker memory model 不强制要求 cache consistency 有更好的拓展性，所以最近的处理器设计趋向使用 weaker memory model。而且 strong memory model 也有使用 memory barriers 的需求 

The issue of when a write becomes visible to another thread is compounded by the compiler's reordering of code. For example, the compiler might decide that it is more efficient to move a write operation later in the program; as long as this code motion does not change the program's semantics, it is free to do so.  If a compiler defers an operation, another thread will not see it until it is performed; this mirrors the effect of caching.

大意：写入何时对另一个线程可见 a write becomes visible to another thread 的问题因编译器对代码的重排（例如：在不改变程序语义的情况下的延迟写入可以提高效率）而变得复杂。但这样做可能会导致直到本线程写入真正执行，另一个线程都不会看到这个写入的新值。

Moreover, writes to memory can be moved earlier in a program; in this case, other threads might see a write before it actually "occurs" in the program.  All of this flexibility is by design -- by giving the compiler, runtime, or hardware the flexibility to execute operations in the optimal order, within the bounds of the memory model, we can achieve higher performance.

大意：对内存的写入也可以在程序中提前进行。通过赋予编译器、运行时或硬件灵活性使得指令在内存模型的范围内以最佳顺序执行操作，可以实现更高的性能。

A simple example of this can be seen in the following code:
``` java
Class Reordering {
    int x = 0, y = 0;
    public void writer() {
        x = 1;
        y = 2;
    }

    public void reader() {
        int r1 = y;
        int r2 = x;
    }
}
```

Let's say that this code is executed in two threads concurrently, and the read of y sees the value 2. Because this write came after the write to x, the programmer might assume that the read of x must see the value 1. However, the writes may have been reordered. If this takes place, then the write to y could happen, the reads of both variables could follow, and then the write to x could take place. The result would be that r1 has the value 2, but r2 has the value 0.

大意：假设这段代码是在两个线程中同时执行的（一个线程执行 writer 方法，一个线程执行 reader 方法），假设读取 y 时得到了 2，又因为程序中 writer 方法对 y 的写入是在对 x 的写入之后，程序员可能会认为此时读取 x 时一定会得到 1。然而，写入的顺序可能会被重排（重排不影响单线程执行 writer 方法的结果），最终可能是 r1 = 2, r2 = 0。例如，执行顺序如下的情况：
1. y = 2; // 在 writer 方法中发生了重排序
2. int r1 = y;
3. int r2 = x;
4. x = 1;

The Java Memory Model describes what behaviors are legal in multithreaded code, and how threads may interact through memory. It describes the relationship between variables in a program and the low-level details of storing and retrieving them to and from memory or registers in a real computer system. It does this in a way that can be implemented correctly using a wide variety of hardware and a wide variety of compiler optimizations.

**Java 内存模型描述了多线程代码中哪些行为是合法的，以及线程如何通过内存进行交互。它描述了程序中的变量之间的关系，以及在真实的计算机系统中存储到内存或寄存器、从内存或寄存器检索变量的低级细节。它以一种可以使用各种硬件和各种编译器优化的方式正确实现。**

Java includes several language constructs, including volatile, final, and synchronized, which are intended to help the programmer describe a program's concurrency requirements to the compiler. The Java Memory Model defines the behavior of volatile and synchronized, and, more importantly, ensures that a correctly synchronized Java program runs correctly on all processor architectures.

Java包括几个语言结构，包括 volatile、final 和 synchronized，**目的是帮助程序员向编译器描述程序的并发性要求。Java 内存模型定义了 volatile 和 synchronized 的行为，更重要的是，它能确保一个正确同步 correctly synchronized 的 Java 程序在所有处理器架构上正确运行。**

> 译注：总结就是，为了提高性能使用的缓存、指令重排（延迟写、提前写）等手段在多处理器、多线程编程中带来了 “写入何时对另一个线程可见” 的问题，内存模型就是描述什么情况下写入对另一个线程一定是可见的。

## Do other languages, like C++, have a memory model?
Most other programming languages, such as C and C++, were not designed with direct support for multithreading. The protections that these languages offer against the kinds of reorderings that take place in compilers and architectures are heavily dependent on the guarantees provided by the threading libraries used (such as pthreads), the compiler used, and the platform on which the code is run.

大多数其他编程语言，如 C 和 C++，在设计时并不直接支持多线程。这些语言对发生在编译器和架构中的各种重排的保护在很大程度上取决于所使用的线程库（如pthreads）、所使用的编译器以及代码运行的平台所提供的保证。

## What is JSR 133 about? JSR 133 的内容是什么？
Since 1997, several serious flaws have been discovered in the Java Memory Model as defined in Chapter 17 of the Java Language Specification. These flaws allowed for confusing behaviors (such as final fields being observed to change their value) and undermined the compiler's ability to perform common optimizations.

自 1997 年以来，在 《Java语言规范》 第 17 章中定义的 Java 内存模型中发现了几个严重的缺陷，这些缺陷允许出现令人困惑的行为（如 final 字段被观察到其值被改变），并破坏了编译器执行普通优化的能力。

The Java Memory Model was an ambitious undertaking; it was the first time that a programming language specification attempted to incorporate a memory model which could provide consistent semantics for concurrency across a variety of architectures. Unfortunately, defining a memory model which is both consistent and intuitive proved far more difficult than expected. JSR 133 defines a new memory model for the Java language which fixes the flaws of the earlier memory model. In order to do this, the semantics of final and volatile needed to change.

大意：这是第一次在编程语言规范中试图纳入一个内存模型，**它可以为各种架构的并发提供一致的语义**。很难但最终还是定义了出来了。

The full semantics are available at [http://www.cs.umd.edu/users/pugh/java/memoryModel](http://www.cs.umd.edu/users/pugh/java/memoryModel) , but the formal semantics are not for the timid. It is surprising, and sobering, to discover how complicated seemingly simple concepts like synchronization really are. Fortunately, you need not understand the details of the formal semantics -- the goal of JSR 133 was to create a set of formal semantics that provides an intuitive framework for how volatile, synchronized, and final work.

大意：我们不一定需要阅读完整的 JMM 语义，因为 **JSR-133 的目的就是创建一套形式语义，为 volatile、synchronized 和 final 如何工作提供了一个直观的框架**。（我们就按照直觉使用就好了，JMM 就是为了保持实际和直觉是一致的）

The goals of JSR 133 include:
- Preserving existing safety guarantees, like type-safety, and strengthening others. For example, variable values may not be created "out of thin air": each value for a variable observed by some thread must be a value that can reasonably be placed there by some thread.

  保留现有的安全保障，如 type-safety，并加强其他保障。
- The semantics of correctly synchronized programs should be as simple and intuitive as possible.

  **正确的同步程序的语义应该是尽可能简单和直观的。**
- The semantics of incompletely or incorrectly synchronized programs should be defined so that potential security hazards are minimized.

  **不完全或不正确的同步程序的语义应该被定义，以便将潜在的安全隐患降到最低。**
- Programmers should be able to reason confidently about how multithreaded programs interact with memory.

  **程序员应该能够自信地推理出多线程程序如何与内存交互。**
- It should be possible to design correct, high performance JVM implementations across a wide range of popular hardware architectures.

  应该可以在各种流行的硬件架构上设计正确的、高性能的 JVM 实现。
- A new guarantee of initialization safety should be provided. If an object is properly constructed (which means that references to it do not escape during construction), then all threads which see a reference to that object will also see the values for its final fields that were set in the constructor, without the need for synchronization.

  应该提供一个新的初始化安全保证。如果一个对象被正确构造（没有引用逃脱发生），那么所有看到对该对象的引用的线程也将看到在构造函数中设置的最终字段的值，而不需要同步。
- There should be minimal impact on existing code.

  这对现有代码的影响应该是最小的。

## What is meant by reordering?
> 译注：大意是在很多情况下，对程序变量（object instance fields, class static fields, and array elements）的访问可能会出现与程序指定的执行顺序不同。例如：
> - 编译器调整指令顺序
> - 处理器的乱序 out-of-order 执行
> - 数据在寄存器、缓存、主存的移动不一定按程序顺序
> 
> 即使存在上面的重排序可能，但是编译器、硬件、运行时都会保证 as-if-serial，即不管怎么重排序，单线程程序中的执行结果不能被改变。但在多线程中需要额外的限制才能保证正确同步。

There are a number of cases in which accesses to program variables (object instance fields, class static fields, and array elements) may appear to execute in a different order than was specified by the program. The compiler is free to take liberties with the ordering of instructions in the name of optimization. Processors may execute instructions out of order under certain circumstances. Data may be moved between registers, processor caches, and main memory in different order than specified by the program.

For example, if a thread writes to field a and then to field b, and the value of b does not depend on the value of a, then the compiler is free to reorder these operations, and the cache is free to flush b to main memory before a. There are a number of potential sources of reordering, such as the compiler, the JIT, and the cache.

The compiler, runtime, and hardware are supposed to conspire to create the illusion of as-if-serial semantics, which means that in a single-threaded program, the program should not be able to observe the effects of reorderings. However, reorderings can come into play in incorrectly synchronized multithreaded programs, where one thread is able to observe the effects of other threads, and may be able to detect that variable accesses become visible to other threads in a different order than executed or specified in the program.

Most of the time, one thread doesn't care what the other is doing. But when it does, that's what synchronization is for.

**大多数时候，一个线程并不关心其他线程在做什么。但当它关心时，这就是同步的作用。**

## What was wrong with the old memory model?
> 译注：大意是旧内存模型存在几个严重的问题，主要体现在 final 和 volatile 上。而且难以理解，所以被广泛违反。

There were several serious problems with the old memory model. It was difficult to understand, and therefore widely violated. For example, the old model did not, in many cases, allow the kinds of reorderings that took place in every JVM. This confusion about the implications of the old model was what compelled the formation of JSR-133.

One widely held belief, for example, was that if final fields were used, then synchronization between threads was unnecessary to guarantee another thread would see the value of the field. While this is a reasonable assumption and a sensible behavior, and indeed how we would want things to work, under the old memory model, it was simply not true. Nothing in the old memory model treated final fields differently from any other field -- meaning synchronization was the only way to ensure that all threads see the value of a final field that was written by the constructor. As a result, it was possible for a thread to see the default value of the field, and then at some later time see its constructed value. This means, for example, that immutable objects like String can appear to change their value -- a disturbing prospect indeed.

The old memory model allowed for volatile writes to be reordered with nonvolatile reads and writes, which was not consistent with most developers intuitions about volatile and therefore caused confusion.

Finally, as we shall see, programmers' intuitions about what can occur when their programs are incorrectly synchronized are often mistaken. One of the goals of JSR-133 is to call attention to this fact.

## What do you mean by “incorrectly synchronized”? 什么是 "不正确的同步"？
Incorrectly synchronized code can mean different things to different people. When we talk about incorrectly synchronized code in the context of the Java Memory Model, we mean any code where

对于不同的人来说，不正确的同步化代码可能意味着不同的事情。当我们在 Java 内存模型的背景下谈论不正确的同步代码时，我们指的是任何代码，其中

1. there is a write of a variable by one thread, 一个线程对一个变量进行了写入
2. there is a read of the same variable by another thread and 另一个线程对同一变量进行了读取，并且
3. the write and read are not ordered by synchronization 写入和读取不按同步顺序进行

> 译注：有时先写后读，有时先读后写，总之没有确定的执行顺序

When these rules are violated, we say we have a data race on that variable. A program with a data race is an incorrectly synchronized program.

当这些规则被违反时，我们就说我们在该变量上有一个数据竞争 data race。一个有数据竞争 data race 的程序就是一个不正确的同步程序。

## What does synchronization do? 同步 synchronization 做了什么？
Synchronization has several aspects. The most well-understood is mutual exclusion -- only one thread can hold a monitor at once, so synchronizing on a monitor means that once one thread enters a synchronized block protected by a monitor, no other thread can enter a block protected by that monitor until the first thread exits the synchronized block.

同步 synchronization 有几个方面。最广为人知的是互斥——一次只能有一个线程持有一个监视器，所以在监视器上同步意味着一旦一个线程进入一个由监视器保护的同步块，其他线程就不能进入由该监视器保护的块，直到第一个线程退出同步块。

But there is more to synchronization than mutual exclusion. Synchronization ensures that memory writes by a thread before or during a synchronized block are made visible in a predictable manner to other threads which synchronize on the same monitor. After we exit a synchronized block, we **release** the monitor, which has the effect of flushing the cache to main memory, so that writes made by this thread can be visible to other threads. Before we can enter a synchronized block, we **acquire** the monitor, which has the effect of invalidating the local processor cache so that variables will be reloaded from main memory. We will then be able to see all of the writes made visible by the previous release.

但是，同步还有比互斥更重要的作用。**同步保证了线程在同步块之前或期间的内存写入会以一种可预测的方式让其他在同一监视器 monitor 上同步的线程看到**。**退出一个同步块后，会释放监视器，会将缓存刷新到内存中，这样这个线程所做的写入就会被其他线程看到。在我们进入一个同步块之前，要获取监视器，本地处理器的缓存失效，这样变量就会从内存中重新加载**。然后，我们将能够看到所有由上一个获得 monitor 的线程写入的值。

Discussing this in terms of caches, it may sound as if these issues only affect multiprocessor machines. However, the reordering effects can be easily seen on a single processor. It is not possible, for example, for the compiler to move your code before an acquire or after a release. When we say that acquires and releases act on caches, we are using shorthand for a number of possible effects.

从缓存的角度讨论这个问题，听起来似乎这些问题只影响多处理器机器。但是，在单处理器上可以很容易看到重排的效果。例如，编译器不可能将你的代码移到获取之前或释放之后。当我们说获取和释放作用于缓存时，我们使用的是一些可能的效果的简写。

The new memory model semantics create a partial ordering on memory operations (read field, write field, lock, unlock) and other thread operations (start and join), where some actions are said to happen before other operations. When one action happens before another, the first is guaranteed to be ordered before and visible to the second. The rules of this ordering are as follows:

新的内存模型语义在内存操作（read field, write field, lock, unlock）和其他线程操作（start and join）上创建了一个偏序关系（部分有序），其中一些操作被认为发生在其他操作之前。**当一个动作发生在另一个动作之前时，第一个动作被保证排在第二个动作之前（不允许重排），并且对第二个动作可见（需要刷新到内存或者使缓存失效，重新从内存中读取）**。这种排序的规则如下。

- Each action in a thread happens before every action in that thread that comes later in the program's order. 

    单线程内，程序顺序中在前面的动作发生在程序顺序在后面的工作之前。
- An unlock on a monitor happens before every subsequent lock on **that same** monitor. 

    监视器上的 unlock 发生在同一监视器上的每个后续的 lock 之前。
- A write to a volatile field happens before every subsequent read of **that same** volatile.

    对一个易失性字段的 write 操作发生在对同一易失性字段的每一次后续的 read 操作之前。
- A call to `start()` on a thread happens before any actions in the started thread.

    对一个线程的 start() 的调用发生在被启动的线程的任何操作之前。
- All actions in a thread happen before any other thread successfully returns from a `join()` on that thread.

    一个线程中的所有操作都发生在任何其他线程从该线程的 join() 中成功返回之前。

This means that any memory operations which were visible to a thread before exiting a synchronized block are visible to any thread after it enters a synchronized block protected by the same monitor, since all the memory operations happen before the release, and the release happens before the acquire.

这意味着任何线程在退出同步块之前可见的内存操作，在它进入由同一监视器保护的同步块之后，都是可见的，因为所有的内存操作都发生在释放之前，而释放发生在获取之前。

Another implication is that the following pattern, which some people use to force a memory barrier, doesn't work:

另一个含义是，有些人用来强制建立内存屏障的以下模式并不可行。

``` java
synchronized (new Object()) {}
```

This is actually a no-op, and your compiler can remove it entirely, because the compiler knows that no other thread will synchronize on the same monitor. You have to set up a happens-before relationship for one thread to see the results of another.

这实际上是一个无用功，你的编译器可以完全删除它，因为编译器知道没有其他线程会在同一个监视器上进行同步。你必须为一个线程看到另一个线程的结果设置一个 happens-before 关系。

> 译注：因为内存屏障在高级语言中不可见，企图通过上面代码来促使底层使用内存屏障是无效的。每次都 new Object()，实际上每次都是一个新的监视器，所以没有意义（即使代码块内有代码，如果有代码，这个时候可能会出现并发的问题）

**Important Note:** Note that it is important for both threads to synchronize on the same monitor in order to set up the happens-before relationship properly. It is not the case that everything visible to thread A when it synchronizes on object X becomes visible to thread B after it synchronizes on object Y. The release and acquire have to "match" (i.e., be performed on the same monitor) to have the right semantics. Otherwise, the code has a data race.

**重要提示：** 请注意，为了正确设置 happen-before 关系，两个线程必须在同一个监视器上进行同步。

## How can final fields appear to change their values?
> 译注：大意是旧内存模型中 final 字段被观察到可变的一个例子。

One of the best examples of how final fields' values can be seen to change involves one particular implementation of the `String` class.

A `String` can be implemented as an object with three fields -- a character array, an offset into that array, and a length. The rationale for implementing `String` this way, instead of having only the character array, is that it lets multiple `String` and `StringBuffer` objects share the same character array and avoid additional object allocation and copying. So, for example, the method `String.substring()` can be implemented by creating a new string which shares the same character array with the original `String` and merely differs in the length and offset fields. For a `String`, these fields are all final fields.

一个 String 可以被实现为一个有三个字段的对象——一个字符数组，一个数组的偏移量，以及一个长度。以这种方式实现 String 可以让多个 String 和 StringBuffer 对象可以共享同一个字符数组，避免额外的对象分配和复制。因此，例如，String.substring() 方法可以通过创建一个新的字符串来实现，该字符串与原始的 String 共享相同的字符数组，只是在长度和偏移量字段上有所不同。对于一个字符串，这些字段都是 final 字段。

```java
String s1 = "/usr/tmp";
String s2 = s1.substring(4);
```

The string `s2` will have an offset of 4 and a length of 4. But, under the old model, it was possible for another thread to see the offset as having the default value of 0, and then later see the correct value of 4, it will appear as if the string "/usr" changes to "/tmp".

字符串 s2 的偏移量为 4，长度为 4。但是，在旧的模型下，另一个线程有可能看到偏移量的默认值为 0，后来又看到正确的值为 4，就会出现偏移值为 0 时字符串 "/usr" 变成了偏移值为 4 时字符串 "/tmp" 的情况。

The original Java Memory Model allowed this behavior; several JVMs have exhibited this behavior. The new Java Memory Model makes this illegal.

最初的 Java 内存模型允许这种行为；一些 JVM 已经表现出这种行为。新的 Java 内存模型使这种行为成为非法。

## How do final fields work under the new JMM? 在新的 JMM 下，final 字段如何工作？
> 译注：大意是在没有 ThisEscape 问题下的，一个对象的 final 字段的值是在其构造函数中设置的，一旦对象被构造出来，在构造函数中分配给最终字段的值无需手动同步将对所有其他线程可见（不会出现上面的 final 的偏移量又 0 变 4 的情况）。如果 final 修饰的是一个引用类型，那只能保证 pointer 是一定的，pointer 的值不一定，可能还需要手动同步。

The values for an object's final fields are set in its constructor. Assuming the object is constructed "correctly", once an object is constructed, the values assigned to the final fields in the constructor will be visible to all other threads without synchronization. In addition, the visible values for any other object or array referenced by those final fields will be at least as up-to-date as the final fields.

What does it mean for an object to be properly constructed? It simply means that no reference to the object being constructed is allowed to "escape" during construction. (See [Safe Construction Techniques](http://www-106.ibm.com/developerworks/java/library/j-jtp0618.html) for examples.)  In other words, do not place a reference to the object being constructed anywhere where another thread might be able to see it; do not assign it to a static field, do not register it as a listener with any other object, and so on. These tasks should be done after the constructor completes, not in the constructor.

```java
class FinalFieldExample {
    final int x;
    int y;
    static FinalFieldExample f;
    public FinalFieldExample() {
        x = 3;
        y = 4;
    }
    
    static void writer() {
        f = new FinalFieldExample();
    }
    
    static void reader() {
        if (f != null) {
            int i = f.x;
            int j = f.y;
        }
    }
}
```

The class above is an example of how final fields should be used. A thread executing `reader` is guaranteed to see the value 3 for `f.x`, because it is final. It is not guaranteed to see the value 4 for `y`, because it is not final. If `FinalFieldExample`'s constructor looked like this:

```java
public FinalFieldExample() { // bad!
    x = 3;
    y = 4;
    // bad construction - allowing this to escape
    global.obj = this;
}
```

then threads that read the reference to `this` from `global.obj` are **not** guaranteed to see 3 for `x`.

The ability to see the correctly constructed value for the field is nice, but if the field itself is a reference, then you also want your code to see the up to date values for the object (or array) to which it points. If your field is a final field, this is also guaranteed. So, you can have a final pointer to an array and not have to worry about other threads seeing the correct values for the array reference, but incorrect values for the contents of the array. Again, by "correct" here, we mean "up to date as of the end of the object's constructor", not "the latest value available".

Now, having said all of this, if, after a thread constructs an immutable object (that is, an object that only contains final fields), you want to ensure that it is seen correctly by all of the other thread, you **still** typically need to use synchronization. There is no other way to ensure, for example, that the reference to the immutable object will be seen by the second thread. The guarantees the program gets from final fields should be carefully tempered with a deep and careful understanding of how concurrency is managed in your code.

There is no defined behavior if you want to use JNI to change final fields.

## What does volatile do? Volatile 会做什么？
> 译注：总结如下
> 1. 对 volatile 的每一次读取都会看到任何线程对该 volatile 的最后一次写入的值（必须确保在写入这些字段后，将其从缓存中刷新到主内存中；在读取一个易失性字段之前，缓存必须无效化，再从主内存中读取值）
> 2. volatile 变量不能相互重新排序，而且对 volatile 变量周围的正常字段访问进行重新排序也不那么容易了 now no longer so easy to reorder normal field accesses around them（无论是否易失性，当线程 A 写到 volatile 字段 f 时，任何对线程 A 可见的东西在线程 B 读到 f 时都是可见的，此时已经类似半个同步）

Volatile fields are special fields which are used for communicating state between threads. Each read of a volatile will see the last write to that volatile by any thread; in effect, they are designated by the programmer as fields for which it is never acceptable to see a "stale" value as a result of caching or reordering. The compiler and runtime are prohibited from allocating them in registers. They must also ensure that after they are written, they are flushed out of the cache to main memory, so they can immediately become visible to other threads. Similarly, before a volatile field is read, the cache must be invalidated so that the value in main memory, not the local processor cache, is the one seen. There are also additional restrictions on reordering accesses to volatile variables.

Under the old memory model, accesses to volatile variables could not be reordered with each other, but they could be reordered with nonvolatile variable accesses. This undermined the usefulness of volatile fields as a means of signaling conditions from one thread to another.

Under the new memory model, it is still true that volatile variables cannot be reordered with each other. The difference is that it is now no longer so easy to reorder normal field accesses around them. Writing to a volatile field has the same memory effect as a monitor release, and reading from a volatile field has the same memory effect as a monitor acquire. In effect, because the new memory model places stricter constraints on reordering of volatile field accesses with other field accesses, volatile or not, anything that was visible to thread A when it writes to volatile field f becomes visible to thread B when it reads f.

Here is a simple example of how volatile fields can be used:
```java
class VolatileExample {
    int x = 0;
    volatile boolean v = false;
    public void writer() {
        x = 42;
        v = true;
    }
    
    public void reader() {
        if (v == true) {
            //uses x - guaranteed to see 42.
        }
    }
}
```

Assume that one thread is calling `writer`, and another is calling `reader`. The write to `v` in `writer` releases the write to `x` to memory, and the read of `v` acquires that value from memory. Thus, if the reader sees the value `true` for `v`, it is also guaranteed to see the write to 42 that happened before it. This would not have been true under the old memory model.  If `v` were not volatile, then the compiler could reorder the writes in `writer`, and `reader`'s read of `x` might see 0.

Effectively, the semantics of volatile have been strengthened substantially, almost to the level of synchronization. Each read or write of a volatile field acts like "half" a synchronization, for purposes of visibility.

**Important Note:** Note that it is important for both threads to access the same volatile variable in order to properly set up the happens-before relationship. It is not the case that everything visible to thread A when it writes volatile field f becomes visible to thread B after it reads volatile field g. The release and acquire have to "match" (i.e., be performed on the same volatile field) to have the right semantics.

## Does the new memory model fix the "double-checked locking" problem?
> 译注：新 JMM 下，使用 volatile 可以解决问题，但还是建议使用 Initialization On Demand Holder idiom 实现 double-checked locking

The (infamous) double-checked locking idiom (also called the multithreaded singleton pattern) is a trick designed to support lazy initialization while avoiding the overhead of synchronization. In very early JVMs, synchronization was slow, and developers were eager to remove it -- perhaps too eager. The double-checked locking idiom looks like this:

```java
// double-checked-locking - don't do this!

private static Something instance = null;

public Something getInstance() {
    if (instance == null) {
        synchronized (this) {
            if (instance == null)
                instance = new Something();
        }
    }
    return instance;
}
```

This looks awfully clever -- the synchronization is avoided on the common code path. There's only one problem with it -- it doesn't work. Why not? The most obvious reason is that the writes which initialize instance and the write to the instance field can be reordered by the compiler or the cache, which would have the effect of returning what appears to be a partially constructed Something. The result would be that we read an uninitialized object. There are lots of other reasons why this is wrong, and why algorithmic corrections to it are wrong. There is no way to fix it using the old Java memory model. More in-depth information can be found at [Double-checked locking: Clever, but broken](http://www.javaworld.com/jw-02-2001/jw-0209-double.html) and [The "Double Checked Locking is broken" declaration](http://www.cs.umd.edu/~pugh/java/memoryModel/DoubleCheckedLocking.html)

> 译注：根据 [JMVS](https://docs.oracle.com/javase/specs/index.html) 3.8 内容，`instance = new Something();` 大致会翻译为四条指令：1. new 申请堆空间；2. dup 把 this 入栈；3. invokespecial 调用构造函数；4. astore_1 赋值，如果重排发生在第 3，4 步，而且执行完赋值之后就被其他线程抢占了，这个时候就会出现 broken 的问题；为什么 volatile 能解决？不允许跨越 volatile 指令排序。（实际不应该以 JVM 指令举例，应该以机器码指令举例，因为指令重排具体指的是编译器编译出机器码时的一个过程，还有 CPU 的乱序执行，还有 JIT 即时编译时的重排，[深入理解Java虚拟机（第3版）](https://book.douban.com/subject/34907497/) 举例使用汇编）

Many people assumed that the use of the volatile keyword would eliminate the problems that arise when trying to use the double-checked-locking pattern. In JVMs prior to 1.5, volatile would not ensure that it worked (your mileage may vary). Under the new memory model, making the instance field volatile will "fix" the problems with double-checked locking, because then there will be a happens-before relationship between the initialization of the Something by the constructing thread and the return of its value by the thread that reads it.

<del>However, for fans of double-checked locking (and we really hope there are none left), the news is still not good. The whole point of double-checked locking was to avoid the performance overhead of synchronization. Not only has brief synchronization gotten a LOT less expensive since the Java 1.0 days, but under the new memory model, the performance cost of using volatile goes up, almost to the level of the cost of synchronization. So there's still no good reason to use double-checked-locking.</del> *Redacted -- volatiles are cheap on most platforms.*

Instead, use the Initialization On Demand Holder idiom, which is thread-safe and a lot easier to understand:

``` java
private static class LazySomethingHolder {
    public static Something something = new Something();
}

public static Something getInstance() {
    return LazySomethingHolder.something;
}
```

This code is guaranteed to be correct because of the initialization guarantees for static fields; if a field is set in a static initializer, it is guaranteed to be made visible, correctly, to any thread that accesses that class.

## What if I'm writing a VM?
You should look at [http://gee.cs.oswego.edu/dl/jmm/cookbook.html](http://gee.cs.oswego.edu/dl/jmm/cookbook.html) .

## Why should I care?
Why should you care? Concurrency bugs are very difficult to debug. They often don't appear in testing, waiting instead until your program is run under heavy load, and are hard to reproduce and trap. You are much better off spending the extra effort ahead of time to ensure that your program is properly synchronized; while this is not easy, it's a lot easier than trying to debug a badly synchronized application.

你为什么需要关心这个？并发错误是很难调试的。它们通常不会在测试中出现，而是等到你的程序在重负荷下运行时才出现，而且很难重现和捕获。你最好提前花费额外的精力来确保你的程序是正确同步的；虽然这并不容易，但比起试图调试一个不同步的应用程序要容易得多。
